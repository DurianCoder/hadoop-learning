17:24:48.552 [main] INFO  com.example.hadoop.MapReduceTest - Starting MapReduceTest on JZ2019C01-0161 with PID 37008 (started by ying.jiang in C:\my_workspace\hadoop)
17:24:48.569 [main] INFO  com.example.hadoop.MapReduceTest - No active profile set, falling back to default profiles: default
17:24:49.259 [main] INFO  com.example.hadoop.MapReduceTest - Started MapReduceTest in 1.083 seconds (JVM running for 4.79)
17:24:49.720 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS
17:24:50.802 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
17:24:50.819 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
17:24:50.820 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
17:24:51.077 [main] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
17:24:51.091 [main] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
17:24:51.122 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
17:24:51.184 [main] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
17:24:51.194 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS
17:24:51.256 [main] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1631477976_0001
17:24:51.259 [main] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
17:24:51.398 [main] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
17:24:51.399 [main] INFO  org.apache.hadoop.mapreduce.Job - Running job: job_local1631477976_0001
17:24:51.401 [Thread-7] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
17:24:51.411 [Thread-7] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
17:24:51.411 [Thread-7] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
17:24:51.412 [Thread-7] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
17:24:51.461 [Thread-7] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
17:24:51.462 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1631477976_0001_m_000000_0
17:24:51.486 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
17:24:51.486 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
17:24:51.496 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
17:24:51.636 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3f17009e
17:24:51.645 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: hdfs://centos01:9000/input/test.txt:0+88
17:24:51.677 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
17:24:51.677 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
17:24:51.678 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080
17:24:51.678 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
17:24:51.678 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
17:24:51.682 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
17:24:51.712 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
17:24:51.872 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - 
17:24:51.875 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output
17:24:51.875 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output
17:24:51.875 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 159; bufvoid = 104857600
17:24:51.875 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600
17:24:51.895 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0
17:24:51.918 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1631477976_0001_m_000000_0 is done. And is in the process of committing
17:24:51.925 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map
17:24:51.925 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1631477976_0001_m_000000_0' done.
17:24:51.936 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1631477976_0001_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=162
		FILE: Number of bytes written=357953
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=88
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=4
		Map output records=18
		Map output bytes=159
		Map output materialized bytes=135
		Input split bytes=100
		Combine input records=18
		Combine output records=12
		Spilled Records=12
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=318242816
	File Input Format Counters 
		Bytes Read=88
17:24:51.936 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1631477976_0001_m_000000_0
17:24:51.940 [Thread-7] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
17:24:51.942 [Thread-7] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
17:24:51.943 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1631477976_0001_r_000000_0
17:24:51.950 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
17:24:51.950 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
17:24:51.951 [pool-8-thread-1] INFO  org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
17:24:52.084 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4cd9b4e7
17:24:52.087 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7fb48e23
17:24:52.090 [pool-8-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
17:24:52.112 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=2658192640, maxSingleShuffleLimit=664548160, mergeThreshold=1754407168, ioSortFactor=10, memToMemMergeOutputsThreshold=10
17:24:52.121 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1631477976_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
17:24:52.143 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1631477976_0001_m_000000_0 decomp: 131 len: 135 to MEMORY
17:24:52.147 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 131 bytes from map-output for attempt_local1631477976_0001_m_000000_0
17:24:52.150 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 131, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->131
17:24:52.151 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
17:24:52.153 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
17:24:52.153 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
17:24:52.173 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
17:24:52.174 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 125 bytes
17:24:52.177 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 131 bytes to disk to satisfy reduce memory limit
17:24:52.178 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 135 bytes from disk
17:24:52.179 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
17:24:52.179 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
17:24:52.181 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 125 bytes
17:24:52.181 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
17:24:52.206 [pool-8-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
17:24:52.229 [Thread-17] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
17:24:52.406 [main] INFO  org.apache.hadoop.mapreduce.Job - Job job_local1631477976_0001 running in uber mode : false
17:24:52.411 [main] INFO  org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
17:24:52.505 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1631477976_0001_r_000000_0 is done. And is in the process of committing
17:24:52.513 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
17:24:52.513 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1631477976_0001_r_000000_0 is allowed to commit now
17:24:52.537 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1631477976_0001_r_000000_0' to hdfs://centos01:9000/output
17:24:52.540 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
17:24:52.541 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1631477976_0001_r_000000_0' done.
17:24:52.541 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1631477976_0001_r_000000_0: Counters: 30
	File System Counters
		FILE: Number of bytes read=464
		FILE: Number of bytes written=358088
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=88
		HDFS: Number of bytes written=81
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=12
		Reduce shuffle bytes=135
		Reduce input records=12
		Reduce output records=12
		Spilled Records=12
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=329252864
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=81
17:24:52.545 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1631477976_0001_r_000000_0
17:24:52.546 [Thread-7] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
17:24:53.414 [main] INFO  org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
17:24:53.415 [main] INFO  org.apache.hadoop.mapreduce.Job - Job job_local1631477976_0001 completed successfully
17:24:53.423 [main] INFO  org.apache.hadoop.mapreduce.Job - Counters: 36
	File System Counters
		FILE: Number of bytes read=626
		FILE: Number of bytes written=716041
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=176
		HDFS: Number of bytes written=81
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=4
		Map output records=18
		Map output bytes=159
		Map output materialized bytes=135
		Input split bytes=100
		Combine input records=18
		Combine output records=12
		Reduce input groups=12
		Reduce shuffle bytes=135
		Reduce input records=12
		Reduce output records=12
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=647495680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=88
	File Output Format Counters 
		Bytes Written=81
